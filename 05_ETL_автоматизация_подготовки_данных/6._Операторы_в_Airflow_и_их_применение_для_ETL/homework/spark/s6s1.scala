/*
spark-submit --packages com.crealytics:spark-excel_2.12:3.5.1_0.20.4,mysql:mysql-connector-java:8.0.33 /var/lib/mydir/d1.scala

–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–æ–∫–µ—Ä "/Users/kostia/Programs:/var/lib/mydir:rw"
*/

import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.sql.functions._
import java.util.Properties

object MySQLExample {
  def main(args: Array[String]): Unit = {
    // –°–æ–∑–¥–∞–µ–º SparkSession
    val spark = SparkSession.builder()
      .appName("MySQLExample")
      .config("spark.driver.extraJavaOptions", "-Dfile.encoding=UTF-8")
      .getOrCreate()

    // –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ MySQL
    val dbUrl = "jdbc:mysql://mysql-db:3306/spark?serverTimezone=UTC"
    val dbUser = "airflow"
    val dbPassword = "airflow"
    val dbDriver = "com.mysql.cj.jdbc.Driver"

    // –ß–∏—Ç–∞–µ–º Excel-—Ñ–∞–π–ª
    val df1 = spark.read
      .format("com.crealytics.spark.excel")
      .option("sheetName", "–õ–∏—Å—Ç1")
      .option("useHeader", "true")
      .option("header", "true")
      .option("treatEmptyValuesAsNulls", "false")
      .option("inferSchema", "true")
      .option("startColumn", 0)
      .option("endColumn", 99)
      .option("timestampFormat", "MM-dd-yyyy HH:mm:ss")
      .load("/var/lib/mydir/d1.xlsx")

    df1.show()

    // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å MySQL
    val connectionProperties = new Properties()
    connectionProperties.put("user", dbUser)
    connectionProperties.put("password", dbPassword)
    connectionProperties.put("driver", dbDriver)

    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ DataFrame –≤ MySQL
    def writeToMySQL(df: DataFrame, tableName: String): Unit = {
      try {
        df.write
          .mode("append")
          .jdbc(dbUrl, tableName, connectionProperties)
        println(s"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ —Ç–∞–±–ª–∏—Ü—É $tableName.")
      } catch {
        case e: Exception =>
          println(s"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ –≤ —Ç–∞–±–ª–∏—Ü—É $tableName: ${e.getMessage}")
      }
    }

    // –ó–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–∞–±–ª–∏—Ü—ã MySQL
    try {
      println("üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ MySQL...")

      writeToMySQL(df1.select("City_code", "Home_city").distinct(), "tabr1")
      writeToMySQL(df1.select("Job_Code", "Job").distinct(), "tabr2")
      writeToMySQL(df1.select("Employee_ID", "Name", "Job_Code").distinct(), "tabr3")
      writeToMySQL(df1.select("Employee_ID", "Name", "City_code").distinct(), "tabr4")

      println("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ MySQL.")

    } catch {
      case e: Exception =>
        println(s"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å MySQL: ${e.getMessage}")
    } finally {
      // –ó–∞–∫—Ä—ã–≤–∞–µ–º SparkSession
      println("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ SparkSession...")
      spark.stop()
    }
  }
}